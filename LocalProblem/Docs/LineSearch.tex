\documentclass{article}
\usepackage{amsmath,amssymb}
\RequirePackage{listings}
\RequirePackage{color}
\RequirePackage{graphicx}
\RequirePackage{hyperref}
%\usepackage{algorithm}
\usepackage{algorithm2e}
\setlength{\parindent}{0pt}
% User-defined colors
\definecolor{DarkGreen}{rgb}{0, .5, 0}
\definecolor{DarkBlue}{rgb}{0, 0, .5}
\definecolor{DarkRed}{rgb}{.5, 0, 0}
\definecolor{LightGray}{rgb}{.95, .95, .95}
\definecolor{White}{rgb}{1.0,1.0,1.0}
\definecolor{darkblue}{rgb}{0,0,0.9}
\definecolor{darkred}{rgb}{0.8,0,0}
\definecolor{darkgreen}{rgb}{0.0,0.85,0}

% Settings for listing class
\lstset{  
  language=[ISO]C++,                       % The default language
  basicstyle=\sf,                          % The basic style
  backgroundcolor=\color{White},       % Set listing background
  keywordstyle=\color{DarkBlue}\bfseries,  % Set keyword style
  commentstyle=\color{DarkGreen}\itshape, % Set comment style
  stringstyle=\color{DarkRed},             % Set string constant style
  extendedchars=true                       % Allow extended characters
  breaklines=true,
  basewidth={0.5em,0.4em},
  fontadjust=true,
  linewidth=\textwidth,
  breakatwhitespace=true,
  lineskip=0ex, %  frame=single
}

\author{Luca Formaggia}
\newcommand{\blue}{\color{blue}}
\newcommand{\red}{\color{red}}
\newcommand{\black}{\color{black}}
\newcommand{\darkred}{\color{darkred}}
\newcommand{\darkgreen}{\color{darkgreen}}
\newcommand{\til}{{$\tilde\null\,\,$}}
\newcommand{\li}{\lstinline}
\newcommand{\cpp}[1]{\li!#1!}
\newcommand{\Exampledir}{run:./../Material/Examples}
\newcommand{\program}[1]{run:./../Material/Examples/src/#1}
\newcommand{\programname}[1]{./../Material/Examples/src/#1}
\newcommand{\onlyprogramname}[1]{Material/Examples/src/#1}
\usepackage{a4wide}
\title{Line Search}
\date{February 2022}
\begin{document}
\maketitle
\section{Line search algorithm for unconstrained minimization problems}
A set of techniques for the unconstrained minimization problem: \emph{Find $\mathbf{x}\in \mathbb{R}^n$
such that}
\[
\mathbf{x}=\operatorname{argmin}_{\mathbf{y}\in\mathbb{R}^n} f(\mathbf{y}),
\]
where $f:\mathbb{R}^n\to\mathbb{R}$ is a cost function, are based on the following general algorithm.
\begin{algorithm}
    \caption{Line Search}
\KwData{$\mathbf{x}_0\in\mathbb{R}^n$, $\epsilon >0$}
Compute a descent direction $\mathbf{d}_k\in\mathbb{R}^n$;\\
Compute a good step $\alpha_k$;\\
Advance $\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k\mathbf{d}_k$;\\
Stop if $\vert f\mathbf{x}_{k+1}\vert\le\epsilon$;\\
\KwResult{$\mathbf{x}=\mathbf{x}_{k+1}$}
\end{algorithm}

In this example we limit to schemes that uses only the knowledge of the gradient $\nabla f$, or of an approximation of it. The structure can be modified with some (but not great) effort to account also for Newton method, which requires the knowledge of the Hessian.
Indeed, I have implemented already some quasi-Newton methods, which build an approximation of the Hessian (or of its inverse).

It is not the scope of this note to give a description of line search algorithms, which can be found in good references like J. Nocedal and S. Wright, Numerical Optimization, or also the nook Numerical Mathematics by A.Quarteroni and F. Saleri.
Here, we want to provide some insight on the algorithmic choices I have made.
\begin{enumerate}
    \item I rely on the \emph{Eigen} library for numerical algebra operations. The use of traits allows changing the basic types and eases a possible refactoring to support a different library;
    \item The descent direction may be done with different algorithms, for instance \emph{gradient} (also called steepest descent), \emph{BFGS} etc. I decided to use polymorphism. So they all derive from a base class, \cpp{DescentDirectionBase}.
    \item I have constructed a factory for the different descent direction classes. However, here, differently than in the example on numerical quadrature, I have not made the factory a global variable, nor implemented the automatic loading of rules in the factory. The reason is that I wanted to show that in simple situations it is not needed to get into that complexity. Of course, the factory and the leading may be in the future adapted for a more plugin-type architecture.
    \item The choice of of the step $\alpha_k$ is here made in the method \cpp{backtrack} with a simple backtracking  (Armijo rule) that imposes the first Wolfe condition (sufficient decrease condition). However, in the aggregate storing the options for the algorithm I have already set a possible coefficient for the second Wolfe condition (curvatore condition), for possible later extensions.
    \item The polymorphic classes for the descent direction are \emph{clonable}. In this specific example it is not so relevant, but in future development it is always better to enable the composition with a polymorphic object support copy operations.  
\end{enumerate}
 
 \section{Bound constrained problem}
 Unconstrained minimization techniques may be easily extended to the box constrained case: 
 \emph{Find $\mathbf{x}\in \mathbb{R}^n$ such that}
 \[
 \begin{cases}
 \mathbf{x}=\operatorname{argmin}_{\mathbf{y}\in\mathbb{R}^n} f(\mathbf{y}),
 \mathbf{a}\le \mathbf{x}\le \mathbf{b}.
 \end{cases}
 \]
 where $\mathbf{a}\in [\{-\infty\}\cup\mathbb{R}]^n$  and $\mathbf{b}\in [\{+\infty\}\cup\mathbb{R}]^n$ are bounds.
 If we indicate with $\Pi$ the projection on the interval $\mathcal{I}$m defined by the bounds, the general algorithms changes into 
 \begin{algorithm}
     \caption{Line Search for Box-Constraints}
     \KwData{$\mathbf{x}_0\in\mathcal{I}$, $\epsilon_1,\epsilon_2 >0$}
     Compute a descent direction $\mathbf{d}_k\in\mathbb{R}^n$;\\
     Compute a good step $\alpha_k$ so that $(\mathbf{x}_k+\alpha_k\mathbf{d}_k)\in\mathcal{I}$;\\
     Advance $\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k\mathbf{d}_k$;\\
     Stop if $\vert f\mathbf{x}_{k+1}\vert\le\epsilon_1$ or $\Vert \mathbf{x}_{k+1}-\mathbf{x}_k\Vert\le\epsilon_2$ ;\\
     \KwResult{$\mathbf{x}=\mathbf{x}_{k+1}$}
 \end{algorithm}

These methods are normally called "projected methods". You find the description in any good book. The version for bounds given by intervals is simple, more  complex situations arise when the constraints are general convex sets.

\section{Other possible extensions}
\begin{itemize}
    \item You can add many other formulas for the computation of descent direction: \emph{L-BFGS}, \emph{gradient with momentum (heavy ball)} ..... 
    \item You can implement a more sophisticated backtracking that enforces also the second Wolfe condition (curvature condition). However, in this case, I will let the user having the possibility of choosing whether activating it or not. The procedure for satisfying a curvature condition is indeed
    quite heavy. The advantage is that you guarantee convergence of certain methods that (according to the theory) may fail if you enforce only the first condition.
    \item More complex, but possible, is to use the present framework in the context of "big data" and implement a \emph{Stochastic gradient} (which is a line search technique). However, maybe in that case is better start from scratch. 
    \item Implement Newton method. Here you need to expand the aggregate providing the input information to account for a function that represent the Hessian. 
\end{itemize}

 

  



\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
